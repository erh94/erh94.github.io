{"posts":[{"title":"Himanshu Upreti - Senior Engineer at Qualcomm Cr&amp;D","text":"Hello! I’m Himanshu Upreti, a Senior Engineer at Qualcomm’s Research and Development division based in Bangalore, India. I was born in the beautiful state of Uttarakhand, India. About MeI hold a Master’s degree in Computer Science and Engineering from the prestigious Indian Institute of Technology Bombay (IIT Bombay). With a strong passion for technology and innovation, I’ve been actively contributing to various projects and research in the field of computer science. My day-to-day work involves tackling exciting challenges in Natural Language Processing (NLP), Computer Vision (CV), and Machine Learning (ML). I am deeply interested in optimizing and deploying models using ONNX, leveraging the power of Git for version control, and exploring the capabilities of PyTorch for advanced research. I’m also proficient in C++, Python, and other technologies that help me create efficient and scalable solutions. Work ExperienceDuring my time at Qualcomm CR&amp;D, I’ve been involved in cutting-edge projects of AI100 that push the boundaries of cloud technology. My expertise includes: Developing and optimizing advanced algorithms in C++ to optimize neural networks. Optimizing source code of SOTA neural network for optimized peformance on AI100 Designing and developing Graph Neural Networks projects Leading cross-functional teams to deliver successful projects. Designing optimized solutions to showcase Qualcomm’s performance in MLPerf. Collaborating with researchers and engineers to drive innovation and improvements in Qualcomm’s AI100 SDK. Education Master of Technology (M.Tech) in Computer Science and Engineering Indian Institute of Technology Bombay (IIT Bombay) Graduated: 2020 LocationI am currently based in Bangalore, India, where I enjoy being part of a vibrant tech community and contributing to the city’s technological advancements. Hobbies and InterestsOutside of my professional life, I have a passion for photography. Capturing moments and telling stories through images has always fascinated me. You can find some of my photography blogs. I also believe in the importance of staying fit and active. In my free time, you’ll often find me at the gym, where I engage in various physical activities to maintain a healthy lifestyle. Thank you for visiting my portfolio page. If you have any inquiries or would like to connect, feel free to reach out! Contact me: [himanshuupreti2010][@][gmail.com] Follow me on LinkedIn for updates and insights into my work.","link":"/2022/08/03/Home/"},{"title":"Exporting an ONNX Model from Caffe2","text":"Caffe2 supports exporting models directly to ONNX. Here are the steps: Install Caffe2 by following the instructions provided in the official Caffe2 documentation. Import the necessary libraries in your Python script: 12from caffe2.python.onnx import backend as caffe2_backendimport torch.onnx Load your Caffe2 model into PyTorch: 12# Assuming you already have a Caffe2 model loadedtorch_model = torch.onnx.load(&quot;path/to/caffe2_model.pb&quot;) Export the PyTorch model to ONNX: 1torch.onnx.export(torch_model, torch.randn(1, 3, 224, 224), &quot;path/to/exported_model.onnx&quot;, verbose=True) Adjust the input shape and replace “path/to/exported_model.onnx” with the desired path to save the ONNX file.","link":"/2023/08/05/technical/Export-model-in-ONNX-from-Caffe2/"},{"title":"Deploy your first ML app using Gradio","text":"Gradio is a Python library that allows you to rapidly create user interfaces for deep learning / machine models. In this tutorial, we will walk through the process of creating a Gradio app for text generation using a pre-trained language model. Step 1 : PrerequisitesBefore you begin, make sure you have the following installed: Python (3.8 or later) For text generation, you can use popular language models like GPT-2, GPT-3, or any other model that suits your needs. Ensure you have the model and its dependencies installed. 123pip install transformers==4.35pip install torch==2.1.1pip install gradio==4.4.1 Step 2: Create a Text Generation FunctionWrite a Python function that takes a prompt as input and generates text using the pre-trained language model. Here’s a simple example using the GPT-2 model from the transformers library: 123456789101112131415161718import torchimport transformersimport gradio as grfrom transformers import AutoModelForCausalLM, GPT2Tokenizermodel_name = &quot;gpt2&quot;model = AutoModelForCasualLM.from_pretrained(model_name)tokenizer = GPT2Tokenizer.from_pretrained(model_name)if tokenizer.pad_token_id is None: tokenizer.pad_token_id = tokenizer.eos_token_iddef generate_text(prompt): inputs = tokenizer([prompt], return_tensors=&quot;pt&quot;) output = model.generate(inputs, max_length=100, do_sample= True, top_k=50, top_p=0.95) generated_text = tokenizer.decode(output[0], skip_special_tokens=True) return generated_text Step 3: Create a Gradio InterfaceNow, create a Gradio interface for your text generation function. Define an interface with an input text box for the prompt and an output text box to display the generated text. 123demo = gr.Interface(fn=generate_text, inputs=&quot;text&quot;, outputs=&quot;text&quot;)demo.launch(server_name=&quot;0.0.0.0&quot;, server_port=7861) Step 4: Run Your Gradio AppSave the script and run it. Gradio will launch a local web interface @ localhost:7861 for your text generation app. With this command you can auto-reload the browser when you make changes to your app. Open your web browser and navigate to the provided URL to interact with the app. 1gradio app.py Step 5 : Interact with Your Text Generation AppEnter a prompt in the input text box and see the generated text in the output text box. Experiment with different prompts to observe how the model responds. This how your first look of app will be Step 6 : (Pro Tip) Lets add some good looks to this AppWe can start with adding the description. So lets do that. We can also add more input to our app to have more control over our output. Update your Interface class with the following changes 1234567891011121314description = &quot;&quot;&quot;# Deploy your first ML app using Gradio&quot;&quot;&quot;inputs = [ gr.Textbox(label=&quot;Prompt text&quot;), gr.Textbox(label=&quot;max-lenth generation&quot;, value=100), gr.Slider(0.0, 1.0, label=&quot;top-p value&quot;, value=0.95), gr.Textbox(label=&quot;top-k&quot;, value=50,),]outputs = [gr.Textbox(label=&quot;Generated Text&quot;)]demo = gr.Interface(fn=generate_text, inputs=inputs, outputs=outputs, allow_flagging=False, description=description)demo.launch(server_name=&quot;0.0.0.0&quot;, server_port=7861) Step 7 : (Pro Tip) Animated text generationAlso text generation is taking time so it will be good if we can show the text word by word right. Lets do that by using some thread and TextIteratorStreamer class. Now update the generate_text method with following changes: 123456789101112131415161718192021from threading import Threadfrom transformers import TextIteratorStreamerstreamer = TextIteratorStreamer(tokenizer, timeout=10.0, skip_prompt=True, skip_special_tokens = True)def generate_text(prompt, max_length, top_p, top_k): inputs = tokenizer([prompt], return_tensors=&quot;pt&quot;) generate_kwargs = dict( inputs, max_length=int(max_length),top_p=float(top_p), do_sample=True, top_k=int(top_k), streamer=streamer ) t = Thread(target=model.generate, kwargs=generate_kwargs) t.start() generated_text=[] for text in streamer: generated_text.append(text) yield &quot;&quot;.join(text) ConclusionCongratulations! You have created a simple Gradio app for text generation. You can further customize the interface, explore different pre-trained models, and enhance the user experience. Gradio simplifies the process of creating interactive machine learning applications, making it easy for users to interact with your models.","link":"/2023/11/29/technical/Deploy-your-first-ML-app-using-Gradio/"},{"title":"Exporting an ONNX Model from TensorFlow","text":"To export a TensorFlow model to the ONNX format, you can use the TensorFlow-ONNX converter. Here’s how: Make sure you have TensorFlow and TensorFlow-ONNX installed. Install them using pip: 1pip install tensorflow tensorflow-onnx Import the required libraries: 12import tensorflow as tfimport tf2onnx Load your TensorFlow model: 1model = tf.keras.applications.ResNet50(weights=&quot;imagenet&quot;) Convert the TensorFlow model to ONNX: 12onnx_model, _ = tf2onnx.convert.from_keras(model)tf2onnx.save_model(onnx_model, &quot;path/to/exported_model.onnx&quot;) Replace “path/to/exported_model.onnx” with the desired path to save the ONNX file.","link":"/2023/08/05/technical/Export-model-in-ONNX-from-Tensorflow/"},{"title":"Himanshu Upreti - Curriculum Vitae","text":"I am a Senior ML Engineer with a focus on Natural Language Processing (NLP), Computer Vision (CV), and Machine Learning (ML). I possess a Master’s degree in Computer Science and Engineering from IIT Bombay and a Bachelor of Technology (B.Tech) degree from GBPUAT Pantnagar. I have a passion for developing cutting-edge technology solutions and am proficient in Python, C++, PyTorch, Git, and have a strong track record of leading successful cross-functional teams. Work ExperienceSenior Engineer at Qualcomm CR&amp;DBangalore, India | Jan 2022 - Present Optimizing source code of SOTA neural network for optimized peformance on AI100 Designing and developing Graph Neural Networks projects Leading cross-functional teams to deliver successful projects. Designing optimized solutions to showcase Qualcomm’s AI100 performance in MLPerf. Collaborating with researchers and engineers to drive innovation and improvements in Qualcomm’s AI100 SDK. Mentored junior team members, fostering a culture of continuous learning and professional growth. Submitted two patents. ProjectsCore Team Member, Cloud AI 100 Apps SDK Contributed as a key member of the core development team for Qualcomm’s Cloud AI 100 Apps SDK. Demonstrated expertise in advancing the SDK’s capabilities, with a focus on cutting-edge Graph Neural Network (GNN) based tools. Lead Engineer for GNN Tool: Led a team of three senior engineers in developing a high-impact GNN-based tool. Played an instrumental role in enhancing the overall functionality and effectiveness of the SDK. Technical Contributions and Engagements: Delivered diverse technical solutions and presentations to the Customer Engineering team. Shared insights, knowledge, and innovation to drive effective adoption and utilization of the SDK’s features. Engineer at Qualcomm CR&amp;DBangalore, India | Jul 2020 - Dec 2022 Submitted two invention diclosure forms Contributed to the development of computer vision applications, leading to enhanced product offerings. Designed and implemented a data pipeline for large-scale machine learning tasks, resulting in increased efficiency and reduced processing time. Developed and optimized advanced algorithms in C++ to optimize neural networks. Enhanced neural network operator supports in AI 100 SDK ProjectsQualcomm Cloud AI 100 Deep Learning Inference Workflow RCNN Exporter Led the creation of the RCNN Exporter tool, solving challenges with dynamic tensor operators in models like Faster RCNN and Mask RCNN. Designed custom ONNX model generation, reimagining core components and integrating Caffe2 ops for optimal AI 100 compiler compatibility. ONNX Runtime execution provider Developed a specialized Execution Provider for ONNX Runtime tailored for AI 100 architecture within an accelerated timeframe. Enabled seamless integration of ONNX models with AI 100 hardware through the creation of the QAic Execution Provider. Utilized AIC compiler and runtime libraries to develop and deliver Execution Provider in AI100 Apps SDK catering to the specific requirements of premium customers. Qualcomm Cloud AI 100 Deep Learning Inference Tools Model Preparator Integral part of the core team that developed the Model Preparator tool. Contributed to creating an inference-friendly model generation solution, optimizing pretrained models by addressing control flow and dynamic tensor challenges. Played a key role in supporting ONNX and TensorFlow models, configuring parameters via YAML format, and executing the tool effectively. Qaic Smart NMS Implemented Smart NMS technique to optimize inference times in object detection models. Orchestrated partitioning of models, capitalizing on AI accelerators for feature extraction and distributing box processing and NMS modules on the host. Achieved enhanced inference speed by leveraging parallelism across AI100 and host, resulting in improved overall performance of object detection pipelines. Research Assistant at CSE Department IIT BombayMumbai, India | May 2017 - May 2020 Held the position of Research Assistant within the prestigious CSE Department at IIT Bombay. Played a pivotal role in the departmental web team, assuming responsibilities for administering web servers, managing web applications, and maintaining the Computer Science and Engineering (CSE) department’s official website. Led interview processes for prospective web team members and departmental Research Assistants, contributing to the selection of skilled individuals to support the department’s technological initiatives. Orchestrated the RA admission process for consecutive years (2018, 2019), demonstrating strong organizational and coordination skills to ensure a smooth and efficient recruitment cycle. ProjectsOnline Grades Evaluation System Led a dynamic team of three students to successfully design, develop, and implement an innovative online grade evaluation system for the Department of Computer Science at IIT Bombay. Utilized cutting-edge technologies including Django, Nginx, HTML, CSS, and Python to create a robust and user-friendly platform. Orchestrated end-to-end project lifecycle, from requirements gathering to deployment, ensuring the system met the unique needs of students, professors, and office staff. Designed a collaborative interface that streamlined evaluations for research-oriented courses, encompassing seminars, R&amp;D projects, and B.Tech/M.Tech/Ph.D. thesis assessments. Notably, the project’s success led to its adoption by other departments as well, exemplifying its widespread value and utility across diverse academic domains. CSE Departmental Website Engineered a modern backend system for the departmental website, adopting a REST API architecture. Successfully migrated data from an older PHP-based website to a Django-rest and MySQL-based REST architecture. Demonstrated technical expertise in backend development, ensuring seamless data transition while enhancing the website’s efficiency and performance. Enabled improved user experience and maintained data integrity through skillful data migration and the implementation of contemporary technologies. Thesis and ResearchMTech Thesis | Fall 2019- Spring 2020Deep Neural Nets for Abnormality Detection in Medical Images | Guide Prof. Suyash Awate Worked on neural-net methods and algorithms for abnormality detection in various datasets of Medical Images Performed binary classification and analyzed one-class classification on CheXRay14 dataset Achieved AUC-score of 0.68 in detection of Infiltration Abnormality in Radiographs Further objective is to perform detection, localization and segmentation of the abnormalities MTech Seminar | Spring 2019Deep Learning Methods for Object Detection on Medical Images | Guide Prof. Suyash Awate Surveyed literature regarding various color normalization techniques in Histopathology Images Study and implementation of various Deep Learning architectures like ResNet and UNET for object detection Proposed and designed a method Patch-CNN for object detection of normal cells and infected cells in thin blood smears images Localized infected cells using Patch-CNN and UNET; achieved AUC-score of 0.98 and 0.96 respectively Education Master of Technology (M.Tech) in Computer Science and Engineering Indian Institute of Technology Bombay (Mumbai, Maharashtra, India) Bachelors of Technology (B.Tech) in Computer Science and Engineering GBPant University of Agriculture and Technology (Pantnagar, Uttarakhand, India) Skills Natural Language Processing (NLP) Computer Vision (CV) Machine Learning (ML) Python C++ PyTorch Git Django Nginx Gradio Hobbies Photography: Check out my photography blogs here. Fitness: Actively go to the gym to maintain a healthy lifestyle. Contact Information Email: er.hupreti[@]gmail.com LinkedIn: Himanshu Upreti Linkedin GitHub: github.com/erh94 Location: Bangalore, India","link":"/curriculum/"},{"title":"Exporting an ONNX Model from PyTorch","text":"PyTorch provides a straightforward way to export models to the ONNX format. Follow these steps: Ensure that you have PyTorch installed. You can install it using pip: 1pip install torch Import the necessary libraries in your Python script: 12import torchimport torchvision Load your PyTorch model: 1model = torchvision.models.resnet18(pretrained=True) Export the model to ONNX: 1torch.onnx.export(model, torch.randn(1, 3, 224, 224), &quot;path/to/exported_model.onnx&quot;, export_params=True) Make sure to replace “path/to/exported_model.onnx” with the desired path to save the ONNX file.","link":"/2023/08/05/technical/Export-model-in-ONNX-from-Pytorch/"},{"title":"Loading an ONNX Model","text":"After exporting the model from your preferred framework to ONNX, you can load it for inference using the onnx package. Here’s an example: 12345678910111213141516import onnx# Load the ONNX modelmodel = onnx.load(&quot;path/to/exported_model.onnx&quot;)# Create an ONNX runtime sessionimport onnxruntime as ortsession = ort.InferenceSession(&quot;path/to/exported_model.onnx&quot;)# Perform inference using the loaded modelinput_name = session.get_inputs()[0].nameoutput_name = session.get_outputs()[0].nameinput_data = np.random.rand(1, 3, 224, 224).astype(np.float32) # Replace with your actual input dataoutput = session.run([output_name], {input_name: input_data})print(output) Remember to replace “path/to/exported_model.onnx” with the path to your exported ONNX model, and provide appropriate input data for inference. That’s it! Now you can export models from different frameworks to ONNX and use the ONNX runtime to load and perform inference with those models.","link":"/2023/08/05/technical/Loading-an-ONNX-model/"},{"title":"Starting with Hexo","text":"This website is developed using Hexo framework. Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/technical/"}],"tags":[{"name":"Senior Engineer","slug":"Senior-Engineer","link":"/tags/Senior-Engineer/"},{"name":"Qualcomm","slug":"Qualcomm","link":"/tags/Qualcomm/"},{"name":"Bangalore","slug":"Bangalore","link":"/tags/Bangalore/"},{"name":"India","slug":"India","link":"/tags/India/"},{"name":"IIT Bombay","slug":"IIT-Bombay","link":"/tags/IIT-Bombay/"},{"name":"CSE","slug":"CSE","link":"/tags/CSE/"},{"name":"Uttarakhand","slug":"Uttarakhand","link":"/tags/Uttarakhand/"},{"name":"Technical","slug":"Technical","link":"/tags/Technical/"},{"name":"ONNX","slug":"ONNX","link":"/tags/ONNX/"},{"name":"Caffe2","slug":"Caffe2","link":"/tags/Caffe2/"},{"name":"HuggingFace","slug":"HuggingFace","link":"/tags/HuggingFace/"},{"name":"Gradio","slug":"Gradio","link":"/tags/Gradio/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Chatbot","slug":"Chatbot","link":"/tags/Chatbot/"},{"name":"Tensorflow","slug":"Tensorflow","link":"/tags/Tensorflow/"},{"name":"PyTorch","slug":"PyTorch","link":"/tags/PyTorch/"}],"categories":[{"name":"portfolio","slug":"portfolio","link":"/categories/portfolio/"},{"name":"technical","slug":"technical","link":"/categories/technical/"}],"pages":[]}